{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The code in this notebook is based on [Richard Liao's implementation of hierarchical attention networks](https://github.com/richliao/textClassifier/blob/master/textClassifierHATT.py) and a related [Google group discussion](https://groups.google.com/forum/#!topic/keras-users/IWK9opMFavQ). The notebook also includes code from [Keras documentation](https://keras.io/) and [blog](https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html) as well as this [word2vec tutorial](http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os \n",
    "os.environ['KERAS_BACKEND'] = 'cntk'\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers, regularizers, optimizers\n",
    "from keras.callbacks import History, CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Download the Amazon reviews data for food from the Internet archive \n",
    "[J. McAuley and J. Leskovec. Hidden factors and hidden topics: understanding rating dimensions with review text. RecSys, 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "r = requests.get(\"https://archive.org/download/amazon-reviews-1995-2013/Gourmet_Foods.txt.gz\")\n",
    "with open(\"Gourmet_Foods.txt.gz\", 'wb') as fp:\n",
    "    fp.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with gzip.open(\"Gourmet_Foods.txt.gz\", \"rb\") as fp:\n",
    "    file_content = fp.read()\n",
    "s = file_content.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"Gourmet_Foods.txt\", \"w\") as fp:\n",
    "    fp.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lst = s.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Extract scores and review texts from file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "text_lst = lst[9:len(lst):11]\n",
    "score_lst = lst[6:len(lst):11]\n",
    "score_lst2 = [sc[14:17] for sc in score_lst]\n",
    "text_lst2 = [txt[13:] for txt in text_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame(data={'text': text_lst2, 'rating': score_lst2})\n",
    "all_data.loc[:, 'rating'] = all_data['rating'].astype(float)\n",
    "all_data.loc[:, 'rating'] = all_data['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Remove medium ratings and convert to binary classification (high vs. low rating).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_data = all_data[all_data['rating'].isin([1, 5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_data = all_data.replace({'rating': {1: '0', 5: '1'}})\n",
    "new_data.loc[:, 'rating'] = new_data['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Extract a balanced subsample and split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_data = pd.concat([new_data[new_data.rating == 0].sample(10000), new_data[new_data.rating == 1].sample(10000)])\n",
    "shuffled = sample_data.iloc[np.random.permutation(20000), :]\n",
    "train_data = shuffled.iloc[:10000, :]\n",
    "test_data = shuffled.iloc[10000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5029\n",
       "1    4971\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5029\n",
       "0    4971\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Set the dimensions of the input and the embedding. Because of the hierarchical nature of the network, the input has to be a 3-dimensional tensor of fixed size (sample_size x n_sentences x n_words). \n",
    "\n",
    "MAX_SENT_LEN : the number of words in each sentence. \n",
    "\n",
    "MAX_SENTS : the number of sentences in each document.\n",
    "\n",
    "Longer documents and sentences will be truncated, shorter ones will be padded with zeros. These numbers should not be much larger than the average sentence and document lengths in the data.    \n",
    "\n",
    "MAX_NB_WORDS : the size of the word encoding (number of most frequent words to keep in the vocabulary)\n",
    "\n",
    "EMBEDDING_DIM : the dimensionality of the word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 50\n",
    "MAX_SENTS = 15\n",
    "MAX_NB_WORDS = 6000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Fit a Keras tokenizer to the most frequent words using the entire training data set as the corpus.\n",
    "Create the training data in the 3d format required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/anargyri/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "reviews = []\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for idx in range(train_data.shape[0]):\n",
    "    text = train_data['text'].iloc[idx]\n",
    "    texts.append(text)\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    reviews.append(sentences)\n",
    "    labels.append(train_data['rating'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "doc_lst = []\n",
    "\n",
    "# keep the MAX_NB_WORDS most frequent words and replace the rest with 'UNK'\n",
    "# truncate to the first MAX_SENTS sentences per doc and MAX_SENT_LENGTH words per sentence\n",
    "\n",
    "for i, sentences in enumerate(reviews):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            words_in_sent = []\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k < MAX_SENT_LENGTH: \n",
    "                    if (word in tokenizer.word_index) and (tokenizer.word_index[word] < MAX_NB_WORDS):\n",
    "                        data[i, j, k] = tokenizer.word_index[word]\n",
    "                        words_in_sent.append(word)\n",
    "                    else:\n",
    "                        data[i, j, k] = MAX_NB_WORDS\n",
    "                        words_in_sent.append('UNK')\n",
    "                    k = k + 1\n",
    "            doc_lst.append(words_in_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Convert the ratings to one-hot categorical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 22249 unique tokens.\n",
      "Shape of data tensor: (10000, 15, 50)\n",
      "Shape of label tensor: (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))\n",
    "\n",
    "y_train = to_categorical(np.asarray(labels)).astype('int32')\n",
    "x_train = data\n",
    "\n",
    "print('Shape of data tensor:', x_train.shape)\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "n_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Train word2vec on the training documents in order to initialize the word embedding. Ignore rare words (min_count=3). Use skip-gram as the training algorithm (sg=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-05 11:14:35,880 : INFO : collecting all words and their counts\n",
      "2017-10-05 11:14:35,881 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-10-05 11:14:35,911 : INFO : PROGRESS: at sentence #10000, processed 149175 words, keeping 5468 word types\n",
      "2017-10-05 11:14:35,946 : INFO : PROGRESS: at sentence #20000, processed 297423 words, keeping 5891 word types\n",
      "2017-10-05 11:14:35,982 : INFO : PROGRESS: at sentence #30000, processed 446111 words, keeping 5978 word types\n",
      "2017-10-05 11:14:36,016 : INFO : PROGRESS: at sentence #40000, processed 597447 words, keeping 5996 word types\n",
      "2017-10-05 11:14:36,037 : INFO : collected 5998 word types from a corpus of 686362 raw words and 45964 sentences\n",
      "2017-10-05 11:14:36,038 : INFO : Loading a fresh vocabulary\n",
      "2017-10-05 11:14:36,054 : INFO : min_count=3 retains 5990 unique words (99% of original 5998, drops 8)\n",
      "2017-10-05 11:14:36,055 : INFO : min_count=3 leaves 686348 word corpus (99% of original 686362, drops 14)\n",
      "2017-10-05 11:14:36,076 : INFO : deleting the raw counts dictionary of 5998 items\n",
      "2017-10-05 11:14:36,077 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2017-10-05 11:14:36,077 : INFO : downsampling leaves estimated 492971 word corpus (71.8% of prior 686348)\n",
      "2017-10-05 11:14:36,078 : INFO : estimated required memory for 5990 words and 100 dimensions: 7787000 bytes\n",
      "2017-10-05 11:14:36,093 : INFO : resetting layer weights\n",
      "2017-10-05 11:14:36,166 : INFO : training model with 6 workers on 5990 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-10-05 11:14:37,174 : INFO : PROGRESS: at 34.70% examples, 854150 words/s, in_qsize 11, out_qsize 0\n",
      "2017-10-05 11:14:38,177 : INFO : PROGRESS: at 71.36% examples, 877556 words/s, in_qsize 11, out_qsize 0\n",
      "2017-10-05 11:14:38,937 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-10-05 11:14:38,947 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-10-05 11:14:38,949 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-10-05 11:14:38,950 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-10-05 11:14:38,952 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-10-05 11:14:38,957 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-10-05 11:14:38,958 : INFO : training on 3431810 raw words (2465317 effective words) took 2.8s, 885318 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# train word2vec on the sentences to initialize the word embedding \n",
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "# use skip-gram\n",
    "word2vec_model = gensim.models.Word2Vec(doc_lst, min_count=3, size=EMBEDDING_DIM, sg=1, workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create the initial embedding matrix from the output of word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 5990 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for word in word2vec_model.wv.vocab:\n",
    "    coefs = np.asarray(word2vec_model.wv[word], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initial embedding\n",
    "embedding_matrix = np.zeros((MAX_NB_WORDS + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None and i < MAX_NB_WORDS:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    elif i == MAX_NB_WORDS:\n",
    "        # index MAX_NB_WORDS in data corresponds to 'UNK'\n",
    "        embedding_matrix[i] = embeddings_index['UNK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define the network.\n",
    "The mask_zero option determines whether masking is performed, i.e. whether the layers ignore the padded zeros in shorter documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# building Hierachical Attention network\n",
    "\n",
    "REG_PARAM = 1e-13\n",
    "l2_reg = regularizers.l2(REG_PARAM)\n",
    "\n",
    "embedding_layer = Embedding(MAX_NB_WORDS + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SENT_LENGTH,\n",
    "                            trainable=True,\n",
    "                            mask_zero=True,\n",
    "                            embeddings_regularizer=l2_reg,\n",
    "                            weights=[embedding_matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define a custom layer implementing the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "CONTEXT_DIM = 100\n",
    "\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, regularizer=None, **kwargs):\n",
    "        self.regularizer = regularizer\n",
    "        self.supports_masking = True\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3        \n",
    "        self.W = self.add_weight(name='W', shape=(input_shape[-1], CONTEXT_DIM), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)\n",
    "        self.b = self.add_weight(name='b', shape=(CONTEXT_DIM,), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)\n",
    "        self.u = self.add_weight(name='u', shape=(CONTEXT_DIM,), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)        \n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.dot(K.tanh(K.dot(x, self.W) + self.b), K.expand_dims(self.u))\n",
    "        ai = K.exp(eij)\n",
    "        alphas = ai / K.sum(ai, axis=1)\n",
    "        if mask is not None:\n",
    "            # use only the inputs specified by the mask\n",
    "            alphas *= K.expand_dims(mask)\n",
    "        weighted_input = K.dot(K.transpose(x), alphas)\n",
    "        return K.reshape(weighted_input, (weighted_input.shape[0],))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = super(AttLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "GRU_UNITS is the dimensionality of each GRU output (the number of GRU units). GRU_IMPL = 2 selects a matricized RNN implementation which is more appropriate for training on a GPU. \n",
    "\n",
    "There are two levels of models in the definition. The sentence model `sentEncoder` is shared across all sentences in the input document.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GPU_IMPL = 2          \n",
    "GRU_UNITS = 100        \n",
    "\n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "l_lstm = Bidirectional(GRU(GRU_UNITS, return_sequences=True, kernel_regularizer=l2_reg, \n",
    "                           implementation=GPU_IMPL))(embedded_sequences)\n",
    "l_att = AttLayer(regularizer=l2_reg)(l_lstm)            \n",
    "sentEncoder = Model(sentence_input, l_att)\n",
    "\n",
    "review_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "l_lstm_sent = Bidirectional(GRU(GRU_UNITS, return_sequences=True, kernel_regularizer=l2_reg, \n",
    "                                implementation=GPU_IMPL))(review_encoder)\n",
    "l_att_sent = AttLayer(regularizer=l2_reg)(l_lstm_sent) \n",
    "preds = Dense(n_classes, activation='softmax', kernel_regularizer=l2_reg)(l_att_sent)\n",
    "model = Model(review_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.5, nesterov=True),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 15, 50)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 15, 200)           740900    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 15, 200)           180600    \n",
      "_________________________________________________________________\n",
      "att_layer_2 (AttLayer)       (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 942,102\n",
      "Trainable params: 942,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fname = 'han_food'\n",
    "history = History()\n",
    "csv_logger = CSVLogger('./{0}_{1}.log'.format(fname, REG_PARAM), separator=',', append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Order training data by the number of sentences in document (as suggested in the [Yang et al.] paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "doc_lengths = [len(r) for r in reviews]\n",
    "ind = np.argsort(doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "56s - loss: 0.6917 - acc: 0.5293\n",
      "Epoch 2/20\n",
      "56s - loss: 0.6908 - acc: 0.5324\n",
      "Epoch 3/20\n",
      "56s - loss: 0.6904 - acc: 0.5347\n",
      "Epoch 4/20\n",
      "56s - loss: 0.6903 - acc: 0.5355\n",
      "Epoch 5/20\n",
      "56s - loss: 0.6900 - acc: 0.5365\n",
      "Epoch 6/20\n",
      "56s - loss: 0.6896 - acc: 0.5375\n",
      "Epoch 7/20\n",
      "56s - loss: 0.6897 - acc: 0.5364\n",
      "Epoch 8/20\n",
      "56s - loss: 0.6891 - acc: 0.5376\n",
      "Epoch 9/20\n",
      "56s - loss: 0.6259 - acc: 0.6745\n",
      "Epoch 10/20\n",
      "57s - loss: 0.5378 - acc: 0.7686\n",
      "Epoch 11/20\n",
      "56s - loss: 0.4529 - acc: 0.7915\n",
      "Epoch 12/20\n",
      "56s - loss: 0.3936 - acc: 0.8477\n",
      "Epoch 13/20\n",
      "57s - loss: 0.5936 - acc: 0.6761\n",
      "Epoch 14/20\n",
      "56s - loss: 0.4996 - acc: 0.7801\n",
      "Epoch 15/20\n",
      "56s - loss: 0.3672 - acc: 0.8545\n",
      "Epoch 16/20\n",
      "57s - loss: 0.3873 - acc: 0.8190\n",
      "Epoch 17/20\n",
      "56s - loss: 0.2796 - acc: 0.8898\n",
      "Epoch 18/20\n",
      "56s - loss: 0.2750 - acc: 0.8994\n",
      "Epoch 19/20\n",
      "56s - loss: 0.2474 - acc: 0.9048\n",
      "Epoch 20/20\n",
      "56s - loss: 0.2149 - acc: 0.9183\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "model.fit(x_train[ind,:,:], y_train[ind,:], epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, shuffle=False, \n",
    "          callbacks=[history, csv_logger], verbose=2)\n",
    "\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_reviews = []\n",
    "test_labels = []\n",
    "test_texts = []\n",
    "\n",
    "for idx in range(test_data.shape[0]):\n",
    "    text = test_data['text'].iloc[idx]\n",
    "    test_texts.append(text)\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    test_reviews.append(sentences)\n",
    "    test_labels.append(test_data['rating'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data2 = np.zeros((len(test_texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "\n",
    "for i, sentences in enumerate(test_reviews):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            words_in_sent = []\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k < MAX_SENT_LENGTH: \n",
    "                    if (word in tokenizer.word_index) and (tokenizer.word_index[word] < MAX_NB_WORDS):\n",
    "                        data2[i, j, k] = tokenizer.word_index[word]\n",
    "                        words_in_sent.append(word)\n",
    "                    else:\n",
    "                        data2[i, j, k] = MAX_NB_WORDS\n",
    "                        words_in_sent.append('UNK')\n",
    "                    k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_test = to_categorical(np.asarray(test_labels))\n",
    "x_test = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8975 \t AUC = 0.9586204479918704\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "print(\"Accuracy = {0} \\t AUC = {1}\".format(accuracy_score(test_labels, preds.argmax(axis=1)),\n",
    "                                           roc_auc_score(test_labels, preds[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['text']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f6204468470>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAF5CAYAAACm4JG+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElS4QwgkiSpcAYQSZJUOAOIJEkq3P8HAenvlkn/wW0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f620443e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = roc_curve(test_labels, preds[:, 1])\n",
    "plot(fpr, tpr)\n",
    "xlabel('FPR')\n",
    "ylabel('TPR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
